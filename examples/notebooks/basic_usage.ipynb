{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAPXplain: Example Usage\n",
    "\n",
    "This notebook demonstrates how to use the SHAPXplain package to integrate SHAP explanations with LLMs, including both synchronous and asynchronous approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Setup and Environment Variables\n",
    "\n",
    "SHAPXplain uses [pydantic-ai](https://github.com/pydantic/pydantic-ai) to interact with LLMs. To use your preferred LLM, you'll need to set the appropriate environment variables:\n",
    "\n",
    "- For OpenAI: `OPENAI_API_KEY`\n",
    "- For Anthropic: `ANTHROPIC_API_KEY`\n",
    "- For other providers, refer to the [pydantic-ai documentation](https://ai.pydantic.dev/)\n",
    "\n",
    "You can set these directly in your environment or use a `.env` file in your project root. Below is an example of how to set them programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment to set environment variables programmatically\n",
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"  # Replace with your actual API key\n",
    "\n",
    "# Or load from .env file\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()  # This will load variables from .env file in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import asyncio\n",
    "import time\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from shap import TreeExplainer\n",
    "from shapxplain import ShapLLMExplainer\n",
    "from pydantic_ai import Agent\n",
    "import nest_asyncio\n",
    "\n",
    "# This is needed for running async code in Jupyter notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"‚úÖ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing the Data and Model\n",
    "\n",
    "First, let's load the Iris dataset, train a random forest classifier, and generate SHAP values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model trained on 150 samples\n",
      "‚úÖ SHAP values generated with shape: (150, 4, 3)\n",
      "‚úÖ Iris classes: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Load data and train model\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Generate SHAP values\n",
    "explainer = TreeExplainer(rf_model)\n",
    "shap_values = explainer.shap_values(X)\n",
    "\n",
    "print(f\"‚úÖ Model trained on {len(X)} samples\")\n",
    "print(f\"‚úÖ SHAP values generated with shape: {np.array(shap_values).shape}\")\n",
    "print(f\"‚úÖ Iris classes: {data.target_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the ShapLLMExplainer\n",
    "\n",
    "Now we'll create our ShapLLMExplainer with the enhanced features including retry logic and caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created LLM agent with model: OpenAIModel(model_name='gpt-4o')\n",
      "‚úÖ ShapLLMExplainer created with features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "‚úÖ Error handling: 3 retries with 1.0s base delay\n"
     ]
    }
   ],
   "source": [
    "# Create an LLM agent - Pydantic-ai will pick up environment var if set\n",
    "llm_agent = Agent(\n",
    "    model=\"openai:gpt-4o\"\n",
    ")  # Can also use other models like \"anthropic:claude-3-opus-20240229\"\n",
    "\n",
    "print(f\"‚úÖ Created LLM agent with model: {llm_agent.model}\")\n",
    "\n",
    "# Instantiate the enhanced SHAPXplain explainer with new parameters\n",
    "llm_explainer = ShapLLMExplainer(\n",
    "    model=rf_model,\n",
    "    llm_agent=llm_agent,\n",
    "    feature_names=data.feature_names,\n",
    "    significance_threshold=0.1,\n",
    "    max_retries=3,  # New: Number of retries for failed API calls\n",
    "    retry_delay=1.0,  # New: Base delay between retries in seconds\n",
    "    cache_size=1000,  # New: Size of the LRU cache for LLM queries\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ ShapLLMExplainer created with features: {data.feature_names}\")\n",
    "print(\n",
    "    f\"‚úÖ Error handling: {llm_explainer.max_retries} retries with {llm_explainer.retry_delay}s base delay\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing a Single Data Point for Explanation\n",
    "\n",
    "Let's prepare a single data point for explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Selected Data Point:\n",
      "\n",
      "Feature             Value     \n",
      "------------------------------\n",
      "sepal length (cm)   5.10      \n",
      "sepal width (cm)    3.50      \n",
      "petal length (cm)   1.40      \n",
      "petal width (cm)    0.20      \n",
      "\n",
      "‚úÖ Predicted class: setosa (100.00% confidence)\n",
      "üìä Class probabilities:\n",
      "  - setosa: 100.00%\n",
      "  - versicolor: 0.00%\n",
      "  - virginica: 0.00%\n",
      "\n",
      "üîç SHAP Values for Predicted Class (setosa):\n",
      "\n",
      "Feature             SHAP Value     \n",
      "-----------------------------------\n",
      "sepal length (cm)   0.0732         \n",
      "sepal width (cm)    0.0025         \n",
      "petal length (cm)   0.2974         \n",
      "petal width (cm)    0.2936         \n"
     ]
    }
   ],
   "source": [
    "# Select a data point (index 0)\n",
    "data_point_index = 0\n",
    "data_point = X[data_point_index]\n",
    "\n",
    "# Print selected data point as a table\n",
    "print(\"\\nüîπ Selected Data Point:\\n\")\n",
    "print(f\"{'Feature':<20}{'Value':<10}\")\n",
    "print(\"-\" * 30)\n",
    "for feature, value in zip(data.feature_names, data_point):\n",
    "    print(f\"{feature:<20}{value:<10.2f}\")\n",
    "\n",
    "# Get predictions\n",
    "prediction_probs = rf_model.predict_proba(data_point.reshape(1, -1))[0]\n",
    "predicted_class_idx = rf_model.predict(data_point.reshape(1, -1))[0]\n",
    "prediction_class = data.target_names[predicted_class_idx]\n",
    "\n",
    "# Print prediction results\n",
    "print(f\"\\n‚úÖ Predicted class: {prediction_class} ({prediction_probs[predicted_class_idx]:.2%} confidence)\")\n",
    "print(\"üìä Class probabilities:\")\n",
    "for i, prob in enumerate(prediction_probs):\n",
    "    print(f\"  - {data.target_names[i]}: {prob:.2%}\")\n",
    "\n",
    "# Extract SHAP values for a specific class and data point\n",
    "class_shap_values = shap_values[data_point_index, :, predicted_class_idx]\n",
    "\n",
    "# Print SHAP values as a table without pandas\n",
    "print(f\"\\nüîç SHAP Values for Predicted Class ({prediction_class}):\\n\")\n",
    "print(f\"{'Feature':<20}{'SHAP Value':<15}\")\n",
    "print(\"-\" * 35)\n",
    "for feature, shap_value in zip(data.feature_names, class_shap_values):\n",
    "    print(f\"{feature:<20}{shap_value:<15.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using Data Contracts for Enhanced Explanations\n",
    "\n",
    "One of the most powerful features of SHAPXplain is the ability to provide domain-specific context through `additional_context`, effectively creating a \"data contract\" that guides the LLM. \n",
    "\n",
    "This data contract provides the LLM with:\n",
    "- Domain-specific terminology and context\n",
    "- Feature descriptions and normal ranges\n",
    "- Target class characteristics\n",
    "- Units of measurement and application context\n",
    "\n",
    "This helps generate more accurate, relevant, and actionable explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Data contract created with the following elements:\n",
      "  - dataset: Iris\n",
      "  - domain: botany\n",
      "  - feature_descriptions: 4 entries\n",
      "  - species_characteristics: 3 entries\n",
      "  - measurement_units: centimeters\n",
      "  - application: Species classification for botanical research\n"
     ]
    }
   ],
   "source": [
    "# Create a comprehensive data contract with domain context\n",
    "iris_context = {\n",
    "    \"dataset\": \"Iris\",\n",
    "    \"domain\": \"botany\",\n",
    "    \"feature_descriptions\": {\n",
    "        \"sepal length\": \"Length of the sepal in cm. Ranges from 4.3 to 7.9 cm across species.\",\n",
    "        \"sepal width\": \"Width of the sepal in cm. Ranges from 2.0 to 4.4 cm across species.\",\n",
    "        \"petal length\": \"Length of the petal in cm. Ranges from 1.0 to 6.9 cm across species.\",\n",
    "        \"petal width\": \"Width of the petal in cm. Ranges from 0.1 to 2.5 cm across species.\",\n",
    "    },\n",
    "    \"species_characteristics\": {\n",
    "        \"setosa\": \"Characterized by small petals, both in length and width. Sepals tend to be wider.\",\n",
    "        \"versicolor\": \"Has medium-sized petals and sepals.\",\n",
    "        \"virginica\": \"Typically has the largest petals and longer sepals.\",\n",
    "    },\n",
    "    \"measurement_units\": \"centimeters\",\n",
    "    \"application\": \"Species classification for botanical research\",\n",
    "}\n",
    "\n",
    "print(\"üìù Data contract created with the following elements:\")\n",
    "for key, value in iris_context.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  - {key}: {len(value)} entries\")\n",
    "    else:\n",
    "        print(f\"  - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Generating explanation using the data contract and LLM...\n",
      "‚úÖ Explanation generated in 8.73 seconds\n",
      "\n",
      "üìã Explanation Summary:\n",
      "The prediction that the flower is setosa is primarily driven by the lengths and widths of its petals and sepals, which are characteristic of this species.\n",
      "\n",
      "üìã Detailed Explanation:\n",
      "In this case, the flower's petals are short and narrow, which is typical for the setosa species. Additionally, the sepal length and width contribute to this classification, with wider sepals being another indicator of setosa. The combination of small petal size and specific sepal dimensions helps distinguish setosa from other species, which usually have larger petals.\n",
      "\n",
      "üìã Recommendations:\n",
      "  1. Ensure future analyses include detailed measurements of petal and sepal dimensions as they are crucial for accurate species classification.\n",
      "  2. Consider using these identified characteristic features to design educational materials or tools that help in the identification of setosa in field research.\n",
      "\n",
      "üìã Confidence Level:\n",
      "high\n",
      "\n",
      "üìã Feature Interactions:\n",
      "  - petal length and petal width: The specific dimensions of both petal length and width jointly signal the setosa species, where small and narrow petals are a distinct identifier.\n"
     ]
    }
   ],
   "source": [
    "# Generate explanation using the data contract\n",
    "print(\"‚è≥ Generating explanation using the data contract and LLM...\")\n",
    "t0 = time.time()\n",
    "\n",
    "explanation = llm_explainer.explain(\n",
    "    shap_values=class_shap_values,\n",
    "    data_point=data_point,\n",
    "    prediction=prediction_probs[predicted_class_idx],\n",
    "    prediction_class=prediction_class,\n",
    "    additional_context=iris_context,\n",
    ")\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"‚úÖ Explanation generated in {elapsed:.2f} seconds\")\n",
    "\n",
    "# Access the explanation components\n",
    "print(\"\\nüìã Explanation Summary:\")\n",
    "print(explanation.summary)\n",
    "\n",
    "print(\"\\nüìã Detailed Explanation:\")\n",
    "print(explanation.detailed_explanation)\n",
    "\n",
    "print(\"\\nüìã Recommendations:\")\n",
    "for i, rec in enumerate(explanation.recommendations, 1):\n",
    "    print(f\"  {i}. {rec}\")\n",
    "\n",
    "print(\"\\nüìã Confidence Level:\")\n",
    "print(explanation.confidence_level)\n",
    "\n",
    "print(\"\\nüìã Feature Interactions:\")\n",
    "if explanation.feature_interactions:\n",
    "    for interaction, desc in explanation.feature_interactions.items():\n",
    "        print(f\"  - {interaction}: {desc}\")\n",
    "else:\n",
    "    print(\"  No significant feature interactions identified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Asynchronous Explanation Generation\n",
    "\n",
    "Now let's demonstrate the new asynchronous capabilities of SHAPXplain, which are particularly useful for web applications and services where you don't want to block the main thread while waiting for the LLM response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Generating explanation asynchronously...\n",
      "‚úÖ Async explanation generated in 8.44 seconds\n",
      "\n",
      "üìã Explanation Summary:\n",
      "The prediction that the flower is of the species 'setosa' is mainly driven by its small petal length and width, which are highly characteristic of this species.\n",
      "\n",
      "üìã Detailed Explanation:\n",
      "The flower being analyzed has certain physical traits that match well with what is typically seen in the 'setosa' species. The petals are quite short and narrow, aligning with the known characteristics of 'setosa', which is recognized for having smaller petals. Additionally, the sepal measurements also support this classification; while the sepal length is relatively average, the width is on the broader side, another trait typical of 'setosa'. These combined factors strongly suggest that the flower belongs to the 'setosa' species, which is commonly distinguished by these smaller, distinctively sized features.\n",
      "\n",
      "üìã Recommendations:\n",
      "  1. Ensure the database of known 'setosa' features is kept updated to provide accurate comparison in future analyses.\n",
      "  2. Educate research teams on the unique physical characteristics of each Iris species to improve initial manual classifications.\n",
      "\n",
      "üìã Confidence Level:\n",
      "high\n",
      "\n",
      "üìã Feature Interactions:\n",
      "  - petal length and width: The combination of both short and narrow petals makes a strong case for this flower being 'setosa', as it exhibits one of the most distinctive patterns seen in this species.\n"
     ]
    }
   ],
   "source": [
    "# Define an async function to get an explanation\n",
    "async def get_async_explanation():\n",
    "    print(\"‚è≥ Generating explanation asynchronously...\")\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Using the same data point and context as before\n",
    "    async_explanation = await llm_explainer.explain_async(\n",
    "        shap_values=class_shap_values,\n",
    "        data_point=data_point,\n",
    "        prediction=prediction_probs[predicted_class_idx],\n",
    "        prediction_class=prediction_class,\n",
    "        additional_context=iris_context,\n",
    "    )\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"‚úÖ Async explanation generated in {elapsed:.2f} seconds\")\n",
    "    return async_explanation\n",
    "\n",
    "\n",
    "# Run the async function\n",
    "async_explanation = asyncio.run(get_async_explanation())\n",
    "\n",
    "# Access the explanation components\n",
    "print(\"\\nüìã Explanation Summary:\")\n",
    "print(async_explanation.summary)\n",
    "\n",
    "print(\"\\nüìã Detailed Explanation:\")\n",
    "print(async_explanation.detailed_explanation)\n",
    "\n",
    "print(\"\\nüìã Recommendations:\")\n",
    "for i, rec in enumerate(async_explanation.recommendations, 1):\n",
    "    print(f\"  {i}. {rec}\")\n",
    "\n",
    "print(\"\\nüìã Confidence Level:\")\n",
    "print(async_explanation.confidence_level)\n",
    "\n",
    "print(\"\\nüìã Feature Interactions:\")\n",
    "if async_explanation.feature_interactions:\n",
    "    for interaction, desc in async_explanation.feature_interactions.items():\n",
    "        print(f\"  - {interaction}: {desc}\")\n",
    "else:\n",
    "    print(\"  No significant feature interactions identified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Processing - Synchronous vs Asynchronous\n",
    "\n",
    "Let's compare the performance of synchronous and asynchronous batch processing. For large batches, asynchronous processing can significantly improve performance by processing multiple items in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Prepared batch data for 5 samples\n",
      "üìä Sample classes: [np.str_('setosa'), np.str_('setosa'), np.str_('setosa'), np.str_('setosa'), np.str_('setosa')]\n"
     ]
    }
   ],
   "source": [
    "# Prepare a small batch of data for demonstration\n",
    "batch_size = 5\n",
    "batch_indices = range(batch_size)\n",
    "\n",
    "# Prepare the batch data\n",
    "data_points = [X[i] for i in batch_indices]\n",
    "predictions = [\n",
    "    rf_model.predict_proba(X[i].reshape(1, -1))[0][\n",
    "        rf_model.predict(X[i].reshape(1, -1))[0]\n",
    "    ]\n",
    "    for i in batch_indices\n",
    "]\n",
    "prediction_classes = [\n",
    "    data.target_names[rf_model.predict(X[i].reshape(1, -1))[0]] for i in batch_indices\n",
    "]\n",
    "shap_values_batch = [\n",
    "    shap_values[i, :, rf_model.predict(X[i].reshape(1, -1))[0]] for i in batch_indices\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Prepared batch data for {batch_size} samples\")\n",
    "print(f\"üìä Sample classes: {prediction_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Starting synchronous batch processing...\n",
      "‚úÖ Synchronous batch processing completed in 38.40 seconds\n",
      "üìä Generated 5 explanations\n",
      "üìù First explanation summary: The prediction that the flower is setosa is primarily driven by the lengths and widths of its petals and sepals, which are characteristic of this species.\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Synchronous batch processing\n",
    "print(\"‚è≥ Starting synchronous batch processing...\")\n",
    "start_time = time.time()\n",
    "\n",
    "sync_batch_response = llm_explainer.explain_batch(\n",
    "    shap_values_batch=shap_values_batch,\n",
    "    data_points=data_points,\n",
    "    predictions=predictions,\n",
    "    prediction_classes=prediction_classes,\n",
    "    additional_context=iris_context,\n",
    ")\n",
    "\n",
    "sync_time = time.time() - start_time\n",
    "print(f\"‚úÖ Synchronous batch processing completed in {sync_time:.2f} seconds\")\n",
    "print(f\"üìä Generated {len(sync_batch_response.responses)} explanations\")\n",
    "print(f\"üìù First explanation summary: {sync_batch_response.responses[0].summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Starting asynchronous batch processing...\n",
      "‚úÖ Asynchronous batch processing completed in 16.81 seconds\n",
      "üìä Generated 5 explanations\n",
      "üìù First explanation summary: The prediction was primarily driven by the size of the petals, which are notably small, and this is a strong indication of the setosa species.\n",
      "\n",
      "‚ö° Performance comparison:\n",
      "  - Synchronous: 38.40 seconds\n",
      "  - Asynchronous: 16.81 seconds\n",
      "  - Speedup: 2.28x faster with asynchronous processing\n",
      "  - Efficiency: 45.68% of theoretical maximum (5x)\n"
     ]
    }
   ],
   "source": [
    "# 6.2 Asynchronous batch processing\n",
    "async def process_batch_async():\n",
    "    print(\"‚è≥ Starting asynchronous batch processing...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    async_batch_response = await llm_explainer.explain_batch_async(\n",
    "        shap_values_batch=shap_values_batch,\n",
    "        data_points=data_points,\n",
    "        predictions=predictions,\n",
    "        prediction_classes=prediction_classes,\n",
    "        additional_context=iris_context,\n",
    "    )\n",
    "\n",
    "    async_time = time.time() - start_time\n",
    "    print(f\"‚úÖ Asynchronous batch processing completed in {async_time:.2f} seconds\")\n",
    "    return async_batch_response, async_time\n",
    "\n",
    "\n",
    "async_batch_response, async_time = asyncio.run(process_batch_async())\n",
    "\n",
    "print(f\"üìä Generated {len(async_batch_response.responses)} explanations\")\n",
    "print(f\"üìù First explanation summary: {async_batch_response.responses[0].summary}\")\n",
    "\n",
    "# Performance comparison\n",
    "speedup = sync_time / async_time\n",
    "print(f\"\\n‚ö° Performance comparison:\")\n",
    "print(f\"  - Synchronous: {sync_time:.2f} seconds\")\n",
    "print(f\"  - Asynchronous: {async_time:.2f} seconds\")\n",
    "print(f\"  - Speedup: {speedup:.2f}x faster with asynchronous processing\")\n",
    "print(\n",
    "    f\"  - Efficiency: {speedup / batch_size:.2%} of theoretical maximum ({batch_size}x)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Error Handling\n",
    "\n",
    "SHAPXplain includes robust error handling with retry logic. Below is a demonstration of how to handle errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Deliberately creating an error situation...\n",
      "‚úÖ Successfully handled input validation error: Length mismatch: shap_values (3) != data_point (4)\n"
     ]
    }
   ],
   "source": [
    "# Example of handling invalid inputs\n",
    "try:\n",
    "    print(\"‚ö†Ô∏è Deliberately creating an error situation...\")\n",
    "    # Deliberately create a mismatch between shap_values and data_point lengths\n",
    "    invalid_explanation = llm_explainer.explain(\n",
    "        shap_values=class_shap_values[:3],  # Only using first 3 values\n",
    "        data_point=data_point,  # Using all 4 features\n",
    "        prediction=prediction_probs[predicted_class_idx],\n",
    "        prediction_class=prediction_class,\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"‚úÖ Successfully handled input validation error: {e}\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"‚úÖ Successfully handled LLM query error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Insights\n",
    "\n",
    "One of the key advantages of batch processing with SHAPXplain is the ability to get cross-case insights. These insights identify common patterns, feature distributions, and general recommendations across the entire batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Batch Summary Statistics:\n",
      "  - Total processed: 5\n",
      "  - Confidence distribution: {<SignificanceLevel.HIGH: 'high'>: 5, <SignificanceLevel.MEDIUM: 'medium'>: 0, <SignificanceLevel.LOW: 'low'>: 0}\n",
      "\n",
      "üìä Common Features:\n",
      "  - petal length (cm): appears in 3/5 cases (60%)\n",
      "  - petal width (cm): appears in 3/5 cases (60%)\n",
      "  - sepal length (cm): appears in 3/5 cases (60%)\n",
      "\n",
      "üìä Batch Insights:\n",
      "  1. The model consistently predicts the same outcome with high confidence, indicating robust performance but potentially limited variability in the test data.\n",
      "  2. The importance of petal length, petal width, and sepal length is consistent across the majority of predictions, suggesting these features are critical in the decision-making process of the model.\n",
      "  3. There are no outliers or unusual predictions, as all predictions are uniformly high, showing no deviation in the model's output.\n",
      "  4. Petal length and petal width frequently interact together, suggesting a strong relationship between these features in influencing the model's predictions.\n"
     ]
    }
   ],
   "source": [
    "# Examine the batch response summary statistics and insights\n",
    "print(\"üìä Batch Summary Statistics:\")\n",
    "print(f\"  - Total processed: {async_batch_response.summary_statistics['total_processed']}\")\n",
    "print(f\"  - Confidence distribution: {async_batch_response.summary_statistics['confidence_summary']}\")\n",
    "\n",
    "print(\"\\nüìä Common Features:\")\n",
    "if async_batch_response.summary_statistics.get(\"common_features\"):\n",
    "    for feature, count in async_batch_response.summary_statistics[\"common_features\"]:\n",
    "        print(f\"  - {feature}: appears in {count}/{batch_size} cases ({count / batch_size:.0%})\")\n",
    "else:\n",
    "    print(\"  No common features found across the batch\")\n",
    "\n",
    "print(\"\\nüìä Batch Insights:\")\n",
    "for i, insight in enumerate(async_batch_response.batch_insights, 1):\n",
    "    print(f\"  {i}. {insight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Medical Example: Using a Different Data Contract\n",
    "\n",
    "Let's demonstrate how the data contract can be customized for a different domain - in this case, medical diagnostics. This showcases the flexibility of SHAPXplain across different domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Medical data contract created\n",
      "‚è≥ Generating medical context explanation...\n",
      "\n",
      "üìã Medical Context Summary:\n",
      "The prediction indicates a diagnosis of Type 1 Diabetes, largely driven by elevated blood pressure (petal length) and a higher BMI (petal width), with age and blood glucose level also playing supportive roles.\n",
      "\n",
      "üìã Medical Recommendations:\n",
      "  1. Encourage regular monitoring of blood pressure and BMI to maintain them within optimal ranges.\n",
      "  2. Schedule regular check-ups to ensure early detection and management of any diabetic symptoms.\n"
     ]
    }
   ],
   "source": [
    "# For demonstration, we'll reuse the same model but with a medical context\n",
    "# In a real-world scenario, you would use an actual medical model\n",
    "\n",
    "# Create a medical data contract\n",
    "medical_context = {\n",
    "    \"domain\": \"medical_diagnosis\",\n",
    "    \"feature_descriptions\": {\n",
    "        \"sepal length\": \"Patient age in years. Normal range varies by condition.\",\n",
    "        \"sepal width\": \"Blood glucose level in mg/dL. Normal range: 70-99 mg/dL fasting.\",\n",
    "        \"petal length\": \"Systolic blood pressure in mmHg. Normal range: <120 mmHg.\",\n",
    "        \"petal width\": \"Body Mass Index. Normal range: 18.5-24.9.\",\n",
    "    },\n",
    "    \"reference_ranges\": {\n",
    "        \"blood_glucose\": {\n",
    "            \"low\": \"<70\",\n",
    "            \"normal\": \"70-99\",\n",
    "            \"prediabetes\": \"100-125\",\n",
    "            \"diabetes\": \">126\",\n",
    "        },\n",
    "        \"blood_pressure\": {\n",
    "            \"normal\": \"<120\",\n",
    "            \"elevated\": \"120-129\",\n",
    "            \"stage1\": \"130-139\",\n",
    "            \"stage2\": \">=140\",\n",
    "        },\n",
    "    },\n",
    "    \"diagnostic_categories\": {\n",
    "        \"setosa\": \"Type 1 Diabetes\",\n",
    "        \"versicolor\": \"Type 2 Diabetes\",\n",
    "        \"virginica\": \"Gestational Diabetes\",\n",
    "    },\n",
    "    \"patient_context\": \"65-year-old male with family history of type 2 diabetes\",\n",
    "}\n",
    "\n",
    "print(\"üìù Medical data contract created\")\n",
    "print(\"‚è≥ Generating medical context explanation...\")\n",
    "\n",
    "# Generate explanation using the medical contract\n",
    "medical_explanation = llm_explainer.explain(\n",
    "    shap_values=class_shap_values,\n",
    "    data_point=data_point,\n",
    "    prediction=prediction_probs[predicted_class_idx],\n",
    "    prediction_class=prediction_class,\n",
    "    additional_context=medical_context,\n",
    ")\n",
    "\n",
    "print(\"\\nüìã Medical Context Summary:\")\n",
    "print(medical_explanation.summary)\n",
    "\n",
    "print(\"\\nüìã Medical Recommendations:\")\n",
    "for i, rec in enumerate(medical_explanation.recommendations, 1):\n",
    "    print(f\"  {i}. {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "This notebook demonstrated the key features of SHAPXplain:\n",
    "\n",
    "1. **Data Contracts**: Providing domain-specific context to enhance explanations\n",
    "2. **Asynchronous API**: Processing explanations in parallel for improved performance\n",
    "3. **Batch Processing**: Efficiently handling multiple predictions with both sync and async methods\n",
    "4. **Error Handling**: Using retry logic to ensure robust operation\n",
    "5. **Batch Insights**: Getting cross-case patterns and recommendations\n",
    "6. **Domain Flexibility**: Adapting explanations to different contexts such as botany or medicine\n",
    "\n",
    "The performance comparison showed that async processing can be significantly faster for batch operations, with a speedup approaching the theoretical maximum of N times faster for N parallel items.\n",
    "\n",
    "SHAPXplain helps bridge the gap between complex SHAP values and human-understandable insights, making machine learning models more interpretable and trustworthy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapxplain",
   "language": "python",
   "name": "shapxplain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
