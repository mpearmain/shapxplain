{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAPXplain: Example Usage\n",
    "\n",
    "This notebook demonstrates how to use the SHAPXplain package to integrate SHAP explanations with LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T12:44:51.642857Z",
     "start_time": "2025-01-17T12:44:51.626712Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from shap import TreeExplainer\n",
    "from shapxplain import ShapLLMExplainer\n",
    "from pydantic_ai import Agent\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply() # Fixes issues with pydantic-ai event loops in jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and train model\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Generate SHAP values\n",
    "explainer = TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LLM agent\n",
    "llm_agent = Agent(model=\"openai:gpt-4o\")\n",
    "\n",
    "# Instantiate the SHAPXplain explainer\n",
    "llm_explainer = ShapLLMExplainer(\n",
    "    model=model,\n",
    "    llm_agent=llm_agent,\n",
    "    feature_names=data.feature_names,\n",
    "    significance_threshold=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an explanation for a specific data point (index 0)\n",
    "data_point = X[0]\n",
    "# Get predictions\n",
    "prediction_probs = model.predict_proba(data_point.reshape(1, -1))[0]\n",
    "predicted_class_idx = model.predict(data_point.reshape(1, -1))[0]\n",
    "prediction_class = data.target_names[predicted_class_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class SHAP values shape: 4\n",
      "Data point shape: 4\n"
     ]
    }
   ],
   "source": [
    "# For multi-class problems, shap_values is a 3D array (instances, features, classes)\n",
    "# Select SHAP values for the predicted class and the specific data point\n",
    "data_point_index = 0  # Index of the data point to explain\n",
    "predicted_class_idx = np.argmax(prediction_probs)  # Index of the predicted class\n",
    "\n",
    "# Extract SHAP values for the data point and class\n",
    "class_shap_values = shap_values[data_point_index][:, predicted_class_idx]\n",
    "\n",
    "# Verify shapes\n",
    "print(\"Class SHAP values shape:\", len(class_shap_values))  # Should match `data_point`\n",
    "print(\"Data point shape:\", len(data_point))  # Should match `class_shap_values`\n",
    "\n",
    "# Ensure the dimensions match\n",
    "assert len(class_shap_values) == len(data_point), \"SHAP values and data point dimensions do not match!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The prediction that the class is 'setosa' is primarily driven by the petal length and petal width, which have measurements typical of this species.\n",
      "\n",
      "Detailed Explanation: In the Iris dataset, setosa is characterized by smaller petal dimensions compared to other species. The measurements of the petal length (1.4 cm) and width (0.2 cm) are consistent with the species setosa. Additionally, the sepal dimensions also support this classification as they align with commonly observed sepal sizes for setosa (5.1 cm length and 3.5 cm width), although they play a lesser role compared to petal dimensions.\n",
      "\n",
      "Recommendations: ['To validate this prediction, cross-reference the predicted class with other botanical characteristics unique to setosa.', 'Consider measuring additional features or using a different set of features if there is a need to improve classification accuracy.']\n",
      "\n",
      "Confidence Level: high\n"
     ]
    }
   ],
   "source": [
    "explanation = llm_explainer.explain(\n",
    "    shap_values=class_shap_values,  # SHAP values for the predicted class\n",
    "    data_point=data_point,\n",
    "    prediction=prediction_probs[predicted_class_idx],\n",
    "    prediction_class=prediction_class,\n",
    "    additional_context={\n",
    "        \"dataset\": \"Iris\",\n",
    "        \"feature_descriptions\": {\n",
    "            \"sepal length\": \"Length of the sepal in cm\",\n",
    "            \"sepal width\": \"Width of the sepal in cm\",\n",
    "            \"petal length\": \"Length of the petal in cm\",\n",
    "            \"petal width\": \"Width of the petal in cm\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Summary:\", explanation.summary)\n",
    "print(\"\\nDetailed Explanation:\", explanation.detailed_explanation)\n",
    "print(\"\\nRecommendations:\", explanation.recommendations)\n",
    "print(\"\\nConfidence Level:\", explanation.confidence_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shapxplain)",
   "language": "python",
   "name": "shapxplain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
